{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task: Evading AI-Generated Text Detection**  \n",
    "\n",
    "### **Objective**  \n",
    "Your goal is to modify the generation process of the **gemma2-2b** model so that generated texts belong to the distribution of fake text detector scores corresponding to humans (i.e. fake text detector thinks that generated texts are actually real). You are given only test set of prompts, and you can't use it for training.\n",
    "\n",
    "### **Provided Data**  \n",
    "1. `test.csv` – Contains a `\"prompt\"` column with test prompts that will be fed into Gemma-2B.  \n",
    "2. **Reference Chart** (`dist.png`) – Shows the detector’s confidence scores for:  \n",
    "   - Human-written text.  \n",
    "   - Baseline gemma2-2b outputs.\n",
    "   - Chat-GPT outputs.\n",
    "\n",
    "### **Constraints**  \n",
    "- **Model Restriction**: Your texts must be generated by provided gemma2-2B. No other LLMs are permitted.\n",
    "- **No training on test**: You can't train/fine-tune the model on the test set of prompts. \n",
    "- **No Prompt/Generation Changes**: The input prompts and generation parameters (e.g., top-k, temperature) are fixed.  \n",
    "- **Fixed `infer` Function**: The submission pipeline is immutable; your solution must work within it.  \n",
    "- **Reproducibility**: Solutions must be deterministic, i.e. identical inputs should produce identical detector-evading outputs.  \n",
    "\n",
    "### **What is allowed**\n",
    "- Finetuning gemma2-2B model for text generation, including tuning of adapters/prefix tuning (again, note: training on test set of prompts is forbidden. You might use prompts that you create by yourself.).\n",
    "- You can use any pre-trained models to help you understand how to change weights/representations of gemma2-2B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we login to HuggingFace and import required modules\n",
    "\n",
    "You need to accept the agreement of [gemma2-2b](https://huggingface.co/google/gemma-2-2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"hf_XXXXXXXXXXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:56:53.648505Z",
     "iopub.status.busy": "2025-05-06T17:56:53.647940Z",
     "iopub.status.idle": "2025-05-06T17:56:53.652803Z",
     "shell.execute_reply": "2025-05-06T17:56:53.652086Z",
     "shell.execute_reply.started": "2025-05-06T17:56:53.648482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import FakeTextDataset\n",
    "from detector import FakeTextDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of pre-trained model that you can use for understanding how to change weights/representation of gemma, we can use SAE trained for this model. Let's install the package for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:56:55.656565Z",
     "iopub.status.busy": "2025-05-06T17:56:55.655913Z",
     "iopub.status.idle": "2025-05-06T17:58:40.654931Z",
     "shell.execute_reply": "2025-05-06T17:58:40.654121Z",
     "shell.execute_reply.started": "2025-05-06T17:56:55.656542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install sae_lens==4.4.5 -q\n",
    "\n",
    "\n",
    "from sae_lens import SAE, HookedSAETransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define config for gemma-2-2b. You can change any parameter here except `model_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:58:40.656515Z",
     "iopub.status.busy": "2025-05-06T17:58:40.656259Z",
     "iopub.status.idle": "2025-05-06T17:58:40.662017Z",
     "shell.execute_reply": "2025-05-06T17:58:40.661118Z",
     "shell.execute_reply.started": "2025-05-06T17:58:40.656497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # data params\n",
    "    # data_path: str = \"/kaggle/input/neoai-2025-deception-fake-text-detector\"\n",
    "    data_path = \"data\"\n",
    "    test_dataset_name: str = \"test.csv\"\n",
    "    num_workers: int = 1\n",
    "    batch_size: int = 40\n",
    "    output_submission_path: str = \"submission.csv\"\n",
    "\n",
    "    # gemma params\n",
    "    device_llm: str = \"cuda:1\"\n",
    "    model_name = \"google/gemma-2-2b\"\n",
    "\n",
    "    # sae params\n",
    "    release: str = \"gemma-scope-2b-pt-res-canonical\"\n",
    "    device_sae: str = \"cuda:1\"\n",
    "    layers = [14, 15, 16, 17, 18]\n",
    "    num_latents_k: int = 16\n",
    "\n",
    "    # detector params\n",
    "    device_detector: str = \"cuda:1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-04T17:18:29.769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3134635dad8c429b960f2ebf114c0900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemma model\n",
    "model = HookedSAETransformer.from_pretrained(Config.model_name, local_files_only=False, device=Config.device_llm)\n",
    "model.eval()\n",
    "\n",
    "# Initialize detector model\n",
    "detector = FakeTextDetector(device=Config.device_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load HC3 dataset for solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wldhx.yadisk-direct\n",
    "! curl -L $(yadisk-direct https://disk.yandex.ru/d/Kz3OP8eQq49ubw) -o data.zip\n",
    "! unzip -qq data.zip\n",
    "! mv gemma_steering_ioai/* ./\n",
    "! rm -rf gemma_steering_ioai data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution identifies steering vectors in Sparse Autoencoder (SAE) latent spaces that distinguish human vs AI generated text, then modifies model behavior during inference. The approach has two core phases:\n",
    "\n",
    "## Phase 1: Identifying Discriminative SAE Features\n",
    "##### Objective: Find latent features that maximally differentiate human vs AI text\n",
    "\n",
    "1. Load human/gpt text pairs using HC3 dataset\n",
    "\n",
    "2. Tokenize text with Gemma-2-2b's tokenizer\n",
    "\n",
    "3. Store SAE activations (features) per-layer\n",
    "\n",
    "4. Train XGBoost classifier for each SAE features from layers\n",
    "\n",
    "5. For each class (human/gpt), identify top ```k``` features\n",
    "\n",
    "6. Store feature indices, max values and deltas (gpt_mean_activations - human_mean_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:12<00:00,  7.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "class HC3(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = pd.read_csv(dataset_path)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        row_values = row.values\n",
    "\n",
    "        sample = {}\n",
    "        sample[\"question\"] = row_values[0]\n",
    "        sample[\"human_answers\"] = row_values[1]\n",
    "        sample[\"chatgpt_answers\"] = row_values[2]\n",
    "        sample[\"source\"] = row_values[3]\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "def gather_residual_activations(model, target_layers, input_ids):\n",
    "    \"\"\"\n",
    "    Gather activations from specific layers of the HookedSAETransformer.\n",
    "\n",
    "    Args:\n",
    "        model: HookedSAETransformer instance\n",
    "        target_layers: List of layer indices to gather activations from\n",
    "        input_ids: Input tensor for the model\n",
    "\n",
    "    Returns:\n",
    "        activations: Dictionary mapping layer indices to activations\n",
    "    \"\"\"\n",
    "    activations = {}\n",
    "\n",
    "    def gather_target_act_hook(layer_idx):\n",
    "        def hook(module, inputs, outputs):\n",
    "            # HookedTransformer blocks output a single tensor (residual stream)\n",
    "            activations[layer_idx] = outputs.detach()\n",
    "            return outputs\n",
    "        return hook\n",
    "\n",
    "    handles = []\n",
    "    for layer_idx in target_layers:\n",
    "        handle = model.blocks[layer_idx].register_forward_hook(\n",
    "            gather_target_act_hook(layer_idx)\n",
    "        )\n",
    "        handles.append(handle)\n",
    "\n",
    "    _ = model(input_ids)\n",
    "\n",
    "    for handle in handles:\n",
    "        handle.remove()\n",
    "\n",
    "    return activations\n",
    "\n",
    "\n",
    "def get_SAE_features(input_ids, model, saes, act_type, target_layers, device):\n",
    "    \"\"\"\n",
    "    Get the features from the SAE (Self-Activating Encoder) based on activations from multiple layers.\n",
    "    Also saves and calculates the mean pooling of the target activations.\n",
    "\n",
    "    Args:\n",
    "        input_ids: The tokenized input (should contain both input_ids and attention_mask).\n",
    "        model: The model from which to gather activations.\n",
    "        sae: The SAE model for encoding the activations.\n",
    "        act_type: The type of activation to return ('sum' or 'avg').\n",
    "        target_layers: A list of layer numbers (indices) from which to gather activations.\n",
    "        device: The device to run the model on (e.g., 'cuda' or 'cpu').\n",
    "        binarize: Whether to binarize the output features.\n",
    "\n",
    "    Returns:\n",
    "        sae_features: A dictionary where keys are layer indices and values are the SAE features for that layer.\n",
    "        mean_pooled_activations: A dictionary where keys are layer indices and values are the mean-pooled activations for that layer.\n",
    "    \"\"\"\n",
    "\n",
    "    activations = gather_residual_activations(model, target_layers, input_ids.to(device))\n",
    "    \n",
    "    sae_features = {}\n",
    "    mean_pooled_activations = {}\n",
    "\n",
    "    for layer_idx, target_act in activations.items():\n",
    "        mean_pooled_activations[layer_idx] = target_act.mean(dim=1).detach().cpu().numpy()\n",
    "\n",
    "        sae_acts = saes[layer_idx].encode(target_act.to(torch.float32))\n",
    "\n",
    "        if act_type == 'sum':\n",
    "            act = sae_acts[0, 1:].sum(0).float().detach().cpu().numpy()\n",
    "        elif act_type == 'avg':\n",
    "            act = sae_acts[0, 1:].mean(0).float().detach().cpu().numpy()\n",
    "\n",
    "        sae_features[layer_idx] = act\n",
    "\n",
    "    return sae_features, mean_pooled_activations\n",
    "\n",
    "\n",
    "dataset = HC3(dataset_path=\"data/hc3.csv\")\n",
    "\n",
    "\n",
    "# Initialize SAE model\n",
    "SAEs = {}\n",
    "for layer in Config.layers:\n",
    "    sae, _, _ = SAE.from_pretrained(\n",
    "        release=Config.release,\n",
    "        sae_id=f\"layer_{layer}/width_{Config.num_latents_k}k/canonical\"\n",
    "    )\n",
    "    sae = sae.to(Config.device_sae)\n",
    "    SAEs[layer] = sae\n",
    "\n",
    "\n",
    "NUM_SAMPLES = 2000\n",
    "TARGET_LAYERS = Config.layers\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "\n",
    "sae_datasets = {}\n",
    "for sample_idx in tqdm(range(NUM_SAMPLES)):\n",
    "    sample = dataset[sample_idx]\n",
    "\n",
    "    tokens_human = tokenizer(sample[\"human_answers\"], truncation = True, max_length = 512, return_tensors = 'pt').input_ids\n",
    "    tokens_gpt = tokenizer(sample[\"chatgpt_answers\"], truncation = True, max_length = 512, return_tensors = 'pt').input_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sae_features_human, _ = get_SAE_features(\n",
    "            input_ids=tokens_human,\n",
    "            model=model,\n",
    "            saes=SAEs,\n",
    "            act_type=\"avg\",\n",
    "            target_layers=TARGET_LAYERS,\n",
    "            device=Config.device_sae\n",
    "        )\n",
    "\n",
    "        sae_features_gpt, _ = get_SAE_features(\n",
    "            input_ids=tokens_gpt,\n",
    "            model=model,\n",
    "            saes=SAEs,\n",
    "            act_type=\"avg\",\n",
    "            target_layers=TARGET_LAYERS,\n",
    "            device=Config.device_sae\n",
    "        )\n",
    "\n",
    "    for layer in TARGET_LAYERS:\n",
    "        dataset_names = [f\"human-{layer}\", f\"gpt-{layer}\"]\n",
    "        for dataset_name in dataset_names:\n",
    "            if dataset_name not in sae_datasets.keys():\n",
    "                sae_datasets[dataset_name] = []\n",
    "\n",
    "            if \"human\" in dataset_name:\n",
    "                sae_datasets[dataset_name].append(sae_features_human[layer])\n",
    "            else:\n",
    "                sae_datasets[dataset_name].append(sae_features_gpt[layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 14\n",
      "(4000, 16384) (4000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1586\n",
      "           1       1.00      1.00      1.00      1614\n",
      "\n",
      "    accuracy                           1.00      3200\n",
      "   macro avg       1.00      1.00      1.00      3200\n",
      "weighted avg       1.00      1.00      1.00      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       414\n",
      "           1       1.00      1.00      1.00       386\n",
      "\n",
      "    accuracy                           1.00       800\n",
      "   macro avg       1.00      1.00      1.00       800\n",
      "weighted avg       1.00      1.00      1.00       800\n",
      "\n",
      "\n",
      "Class 'human' feature importance (gain):\n",
      "f8807: 0.9517\n",
      "f11740: 0.0251\n",
      "f9059: 0.0153\n",
      "\n",
      "Class 'gpt' feature importance (gain):\n",
      "f8807: 0.5984\n",
      "f11740: 0.3810\n",
      "f12858: 0.0172\n",
      "--------------------------------------------------------------------------------\n",
      "Layer: 15\n",
      "(4000, 16384) (4000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1586\n",
      "           1       1.00      1.00      1.00      1614\n",
      "\n",
      "    accuracy                           1.00      3200\n",
      "   macro avg       1.00      1.00      1.00      3200\n",
      "weighted avg       1.00      1.00      1.00      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       414\n",
      "           1       1.00      1.00      1.00       386\n",
      "\n",
      "    accuracy                           1.00       800\n",
      "   macro avg       1.00      1.00      1.00       800\n",
      "weighted avg       1.00      1.00      1.00       800\n",
      "\n",
      "\n",
      "Class 'human' feature importance (gain):\n",
      "f13613: 0.8019\n",
      "f8708: 0.1210\n",
      "f6266: 0.0719\n",
      "\n",
      "Class 'gpt' feature importance (gain):\n",
      "f13613: 0.6987\n",
      "f6266: 0.2261\n",
      "f10583: 0.0569\n",
      "--------------------------------------------------------------------------------\n",
      "Layer: 16\n",
      "(4000, 16384) (4000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1586\n",
      "           1       1.00      1.00      1.00      1614\n",
      "\n",
      "    accuracy                           1.00      3200\n",
      "   macro avg       1.00      1.00      1.00      3200\n",
      "weighted avg       1.00      1.00      1.00      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       414\n",
      "           1       1.00      1.00      1.00       386\n",
      "\n",
      "    accuracy                           1.00       800\n",
      "   macro avg       1.00      1.00      1.00       800\n",
      "weighted avg       1.00      1.00      1.00       800\n",
      "\n",
      "\n",
      "Class 'human' feature importance (gain):\n",
      "f8689: 0.8912\n",
      "f14919: 0.1000\n",
      "f6689: 0.0072\n",
      "\n",
      "Class 'gpt' feature importance (gain):\n",
      "f8689: 0.8965\n",
      "f14919: 0.0654\n",
      "f6689: 0.0357\n",
      "--------------------------------------------------------------------------------\n",
      "Layer: 17\n",
      "(4000, 16384) (4000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1586\n",
      "           1       1.00      1.00      1.00      1614\n",
      "\n",
      "    accuracy                           1.00      3200\n",
      "   macro avg       1.00      1.00      1.00      3200\n",
      "weighted avg       1.00      1.00      1.00      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       414\n",
      "           1       1.00      1.00      1.00       386\n",
      "\n",
      "    accuracy                           1.00       800\n",
      "   macro avg       1.00      1.00      1.00       800\n",
      "weighted avg       1.00      1.00      1.00       800\n",
      "\n",
      "\n",
      "Class 'human' feature importance (gain):\n",
      "f385: 0.8132\n",
      "f9095: 0.1239\n",
      "f6079: 0.0481\n",
      "\n",
      "Class 'gpt' feature importance (gain):\n",
      "f385: 0.6136\n",
      "f6079: 0.3761\n",
      "f12191: 0.0046\n",
      "--------------------------------------------------------------------------------\n",
      "Layer: 18\n",
      "(4000, 16384) (4000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1586\n",
      "           1       1.00      1.00      1.00      1614\n",
      "\n",
      "    accuracy                           1.00      3200\n",
      "   macro avg       1.00      1.00      1.00      3200\n",
      "weighted avg       1.00      1.00      1.00      3200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       414\n",
      "           1       1.00      1.00      1.00       386\n",
      "\n",
      "    accuracy                           1.00       800\n",
      "   macro avg       1.00      1.00      1.00       800\n",
      "weighted avg       1.00      1.00      1.00       800\n",
      "\n",
      "\n",
      "Class 'human' feature importance (gain):\n",
      "f16302: 0.6062\n",
      "f4841: 0.2308\n",
      "f12685: 0.0975\n",
      "\n",
      "Class 'gpt' feature importance (gain):\n",
      "f10076: 0.7675\n",
      "f4841: 0.1216\n",
      "f16302: 0.0570\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "TOP_FEATURES = {}\n",
    "choose_top_n_latents = 3\n",
    "\n",
    "for layer in TARGET_LAYERS:\n",
    "    print(f\"Layer: {layer}\")\n",
    "\n",
    "    data_human = np.array(sae_datasets[f\"human-{layer}\"])\n",
    "    data_gpt = np.array(sae_datasets[f\"gpt-{layer}\"])\n",
    "\n",
    "    data = np.concatenate([data_human, data_gpt], axis=0)\n",
    "\n",
    "    # 0 - human\n",
    "    # 1 - gpt\n",
    "    labels = np.concatenate([np.zeros(data_human.shape[0]), np.ones(data_gpt.shape[0])])\n",
    "\n",
    "    print(data.shape, labels.shape)\n",
    "\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(data, labels, test_size=0.2, random_state=21)\n",
    "\n",
    "    clf = XGBClassifier(max_depth=2, alpha=1, random_state=21)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = clf.predict(X_train)\n",
    "    print(classification_report(y_train, train_pred, labels=[0, 1]))\n",
    "\n",
    "    eval_pred = clf.predict(X_eval)\n",
    "    print(classification_report(y_eval, eval_pred, labels=[0, 1]))\n",
    "\n",
    "    # find important latents\n",
    "    num_classes = clf.n_classes_\n",
    "    booster = clf.get_booster()\n",
    "    feature_names = [f\"f{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "    per_class_importance = {i: np.zeros(X_train.shape[1]) for i in range(num_classes)}\n",
    "\n",
    "    trees = booster.trees_to_dataframe()\n",
    "\n",
    "    n_estimators = clf.n_estimators\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        class_trees = trees.iloc[class_idx::num_classes]\n",
    "\n",
    "        gains = class_trees.groupby('Feature')['Gain'].sum().reset_index()\n",
    "\n",
    "        for _, row in gains.iterrows():\n",
    "            feat_name = row['Feature']\n",
    "            if feat_name.startswith('f'):\n",
    "                feat_idx = int(feat_name[1:])\n",
    "            else:\n",
    "                try:\n",
    "                    feat_idx = feature_names.index(feat_name)\n",
    "                except ValueError:\n",
    "                    continue  # skip 'Leaf' nodes\n",
    "\n",
    "            per_class_importance[class_idx][feat_idx] = row['Gain']\n",
    "\n",
    "        total = per_class_importance[class_idx].sum()\n",
    "        if total > 0:\n",
    "            per_class_importance[class_idx] /= total\n",
    "\n",
    "    chosen_features = []\n",
    "    class_names = [\"human\", \"gpt\"]\n",
    "    for class_idx in range(len(class_names)):\n",
    "        print(f\"\\nClass '{class_names[class_idx]}' feature importance (gain):\")\n",
    "        sorted_idx = np.argsort(per_class_importance[class_idx])[::-1]\n",
    "\n",
    "        for idx in sorted_idx[:choose_top_n_latents]:  # top n latents for every class\n",
    "            feat_name = feature_names[idx] if isinstance(feature_names, list) else f\"f{idx}\"\n",
    "            print(f\"{feat_name}: {per_class_importance[class_idx][idx]:.4f}\")\n",
    "            chosen_features.append(idx)\n",
    "    chosen_features = np.unique(chosen_features)\n",
    "    chosen_features_max_values = [data[:, idx].max() for idx in chosen_features]\n",
    "    chosen_features_delta = [data[labels == 1, idx].mean() - data[labels == 0, idx].mean() for idx in chosen_features]\n",
    "\n",
    "    TOP_FEATURES[layer] = {\n",
    "        \"feature_idxs\": chosen_features,\n",
    "        \"feature_max_values\": chosen_features_max_values,\n",
    "        \"delta\": chosen_features_delta}\n",
    "\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Model Steering via Activation Hooks\n",
    "#### Objective: Modify model outputs using identified features during inference\n",
    "\n",
    "##### Steering Vector for each layer and feature (index from SAE latent space):\n",
    "\n",
    "```total_steering += comp[\"delta\"] * comp[\"strength\"] * comp[\"vector\"]```\n",
    "\n",
    "Parameters:\n",
    "- Vectors derived from SAE decoders (```SAEs[layer].W_dec```)\n",
    "\n",
    "- Scaled by activation ```delta``` (direction) and ```strength``` (magnitude). You can finetune them and understand how they change the generation.\n",
    "\n",
    "\n",
    "\n",
    "##### Steered inference, generate text with active hooks:\n",
    "\n",
    "```with model.hooks(fwd_hooks=hooks):```\n",
    "\n",
    "This code modifies residual stream activations at target layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-04T17:18:29.769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "STEERING_DICT = {}\n",
    "for layer in TARGET_LAYERS:\n",
    "    STEERING_DICT[layer] = []\n",
    "    for feature, max_feature_value, delta in zip(\n",
    "        TOP_FEATURES[layer][\"feature_idxs\"],\n",
    "        TOP_FEATURES[layer][\"feature_max_values\"],\n",
    "        TOP_FEATURES[layer][\"delta\"]\n",
    "    ):\n",
    "        STEERING_DICT[layer].append(\n",
    "            {\n",
    "                \"vector\": SAEs[layer].W_dec[feature].to(Config.device_sae),\n",
    "                \"strength\": 1,\n",
    "                \"max_act\": max_feature_value,\n",
    "                \"delta\": delta\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "TOTAL_STEERING_VECTORS = {}\n",
    "for layer, components in STEERING_DICT.items():\n",
    "    total_steering = torch.zeros_like(components[0][\"vector\"])\n",
    "    for comp in components:\n",
    "        total_steering += comp[\"delta\"] * comp[\"strength\"] * comp[\"vector\"]\n",
    "    TOTAL_STEERING_VECTORS[layer] = total_steering\n",
    "\n",
    "\n",
    "def create_steering_hook(layer: int, steering_vector: torch.Tensor):\n",
    "    def hook_func(activations: torch.Tensor, hook) -> torch.Tensor:\n",
    "        return activations + steering_vector.to(activations.device)\n",
    "    return hook_func\n",
    "\n",
    "\n",
    "hooks = []\n",
    "for layer, steering_vector in TOTAL_STEERING_VECTORS.items():\n",
    "    hook_name = SAEs[layer].cfg.hook_name\n",
    "    hook_fn = create_steering_hook(layer, steering_vector.to(Config.device_llm))\n",
    "    hooks.append((hook_name, hook_fn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below there is infer function that takes model and some arguments and generates submission. The code of this function cannot be changed (however arguments can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(\n",
    "        config: Config,\n",
    "        model: torch.nn.Module,\n",
    "        max_new_tokens: int = 128,\n",
    "        stop_at_eos: bool = True,\n",
    "        prepend_bos: bool = True,\n",
    "        verbose: bool = False,\n",
    "        skip_special_tokens: bool = True\n",
    "    ) -> None:\n",
    "    dataset = FakeTextDataset(os.path.join(config.data_path, config.test_dataset_name), mode=\"test\")\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "    submission = {\"prompt\": [], \"generation\": []}\n",
    "    for batch in tqdm(dataloader):\n",
    "        prompts = batch[\"prompt\"]\n",
    "\n",
    "        submission[\"prompt\"].extend(prompts)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_ids = model.to_tokens(prompts, prepend_bos=True)\n",
    "            output = model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                stop_at_eos=stop_at_eos,\n",
    "                prepend_bos=prepend_bos,\n",
    "                verbose=verbose\n",
    "            ).cpu().numpy()\n",
    "        generated_texts = model.tokenizer.batch_decode(output, skip_special_tokens=skip_special_tokens)\n",
    "        submission[\"generation\"].extend(generated_texts)\n",
    "\n",
    "    submission = pd.DataFrame(submission)\n",
    "\n",
    "    submission.prompt = submission.prompt.apply(lambda x: x.replace('\"', \"'\"))\n",
    "    submission.generation = submission.generation.apply(lambda x: x.replace('\"', '\"'))\n",
    "\n",
    "    submission = submission.astype(pd.StringDtype())\n",
    "\n",
    "    submission.to_csv(config.output_submission_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:38<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "with model.hooks(fwd_hooks=hooks):\n",
    "    infer(config=Config, model=model, max_new_tokens=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below there is metric code which will be infered on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:59:21.770094Z",
     "iopub.status.busy": "2025-05-06T17:59:21.769404Z",
     "iopub.status.idle": "2025-05-06T17:59:21.781340Z",
     "shell.execute_reply": "2025-05-06T17:59:21.780436Z",
     "shell.execute_reply.started": "2025-05-06T17:59:21.770072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "class TextComparator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: str = \"cpu\",\n",
    "        model_dir: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    ) -> None:\n",
    "        self.model = SentenceTransformer(model_dir, device=device)\n",
    "        self.embedding_cache = {}\n",
    "\n",
    "    def get_embeddings(self, texts: Union[str, List[str]]) -> np.ndarray:\n",
    "        single_text = isinstance(texts, str)\n",
    "        if single_text:\n",
    "            texts = [texts]\n",
    "\n",
    "        uncached_texts = [t for t in texts if t not in self.embedding_cache]\n",
    "        if uncached_texts:\n",
    "            new_embeddings = self.model.encode(uncached_texts, convert_to_numpy=True)\n",
    "            for text, embedding in zip(uncached_texts, new_embeddings):\n",
    "                self.embedding_cache[text] = embedding\n",
    "\n",
    "        embeddings = np.array([self.embedding_cache[t] for t in texts])\n",
    "\n",
    "        return embeddings[0] if single_text else embeddings\n",
    "\n",
    "    def similarity(\n",
    "        self, \n",
    "        text1: Union[str, List[str]], \n",
    "        text2: Union[str, List[str]]\n",
    "    ) -> Union[float, np.ndarray]:\n",
    "        emb1 = self.get_embeddings(text1)\n",
    "        emb2 = self.get_embeddings(text2)\n",
    "\n",
    "        return np.diag(util.cos_sim(emb1, emb2).numpy())\n",
    "\n",
    "\n",
    "class FakeTextDetector:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: str = \"cuda:1\",\n",
    "        model_dir: str = \"hyunseoki/ReMoDetect-deberta\"\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "\n",
    "    def get_score(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=512, padding=True).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            score = self.model(**inputs).logits.cpu().detach().numpy()\n",
    "        return score\n",
    "\n",
    "\n",
    "def score(\n",
    "    solution: pd.DataFrame,\n",
    "    submission: pd.DataFrame,\n",
    "    row_id_column_name: str,\n",
    "    similarity_threshold: float = 0.65,\n",
    "    score_threshold_low: float = -2.0,\n",
    "    score_threshold_high: float = 2.0\n",
    ") -> float:\n",
    "    assert solution.shape == submission.shape\n",
    "    assert (solution[row_id_column_name] == submission[row_id_column_name]).all()\n",
    "\n",
    "    # comparator = TextComparator()\n",
    "    detector = FakeTextDetector()\n",
    "\n",
    "    # similarities = comparator.similarity(\n",
    "    #     solution[\"generation\"].tolist(),\n",
    "    #     submission[\"generation\"].tolist()\n",
    "    # )\n",
    "    similarities = np.ones(solution.shape[0])\n",
    "\n",
    "    steered_texts = submission[\"generation\"].tolist()\n",
    "\n",
    "    scores = []\n",
    "    for steered_text, similarity_score in tqdm(zip(steered_texts, similarities)):\n",
    "        if similarity_score < similarity_threshold:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "\n",
    "        scores_i = detector.get_score(steered_text).item()\n",
    "        scores.append(scores_i)\n",
    "\n",
    "    similarity_mask = similarities > similarity_threshold\n",
    "    deceptions = (np.array(scores) > score_threshold_low) & (np.array(scores) < score_threshold_high) & similarity_mask\n",
    "    return deceptions.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:59:32.329695Z",
     "iopub.status.busy": "2025-05-06T17:59:32.328886Z",
     "iopub.status.idle": "2025-05-06T17:59:32.355525Z",
     "shell.execute_reply": "2025-05-06T17:59:32.354539Z",
     "shell.execute_reply.started": "2025-05-06T17:59:32.329660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:04, 100.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(Config.output_submission_path)\n",
    "\n",
    "metric = score(solution=submission, submission=submission, row_id_column_name=\"prompt\")\n",
    "print(metric.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_texts = submission[\"generation\"]\n",
    "prompts = submission[\"prompt\"]\n",
    "new_p = []\n",
    "new_t = []\n",
    "for t, p in zip(generated_texts, prompts):\n",
    "    if p.replace('\"', \"'\") not in submission.prompt.tolist():\n",
    "        continue\n",
    "    new_p.append(p)\n",
    "    new_t.append(t)\n",
    "\n",
    "scores_generated = []\n",
    "for g_text in generated_texts:\n",
    "    with torch.no_grad():\n",
    "        scores_generated.append(detector.get_score([g_text])[0].item())\n",
    "\n",
    "visualize_df = pd.DataFrame({\n",
    "    'value': scores_generated,\n",
    "    'hue': ['gemma'] * len(scores_generated)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.histplot(data=visualize_df, x='value', hue='hue')\n",
    "\n",
    "plt.axvline(x=-2, color=\"red\", linestyle=\"--\")\n",
    "plt.axvline(x=2, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.title(\"wiki_csai\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12179703,
     "sourceId": 100470,
     "sourceType": "competition"
    },
    {
     "datasetId": 7327148,
     "sourceId": 11674740,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
